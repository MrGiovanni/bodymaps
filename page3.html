<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>How to Participate</title>

    <!-- Site meta -->
    <meta property="og:type" content="website" />
    <meta name="twitter:card" content="summary" />

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-9968XPLKX3"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'G-9968XPLKX3');
    </script>

    <link rel="icon" href="./images/bodymap-new.png">
    <link rel="stylesheet" href="./public/css/navigator.css">
    <link rel="stylesheet" href="./public/css/kits23/reset.css">
    <link rel="stylesheet" href="./public/css/kits23/page.css">
    <script>
        const username = "";
    </script>
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"
        integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>

    <link rel="stylesheet" href="./public/css/kits23/header.css">
    <script src="./public/js/kits23/header.js"></script>

    <link rel="stylesheet" href="./public/css/kits23/footer.css">

    <link rel="stylesheet" href="./public/css/kits23/home.css">
    <script src="./public/js/kits23/home.js"></script>

    <!-- Material Icons -->
    <link
        href="https://fonts.googleapis.com/css?family=Material+Icons%7CMaterial+Icons+Outlined%7CMaterial+Icons+Two+Tone%7CMaterial+Icons+Round%7CMaterial+Icons+Sharp"
        rel="stylesheet">

    <meta name="robots" content="index, follow" />
    <link href="index.html" rel="canonical">
</head>

<body>

    <nav id="navbar">
        <div class="logo">
            <a href="index.html"><img src="./images/bodymap-new.png" alt="Logo"></a>
        </div>
        <ul class="nav-links">
            <li><a href="page1.html">Item 1</a></li>
            <li><a href="page2.html">Item 2</a></li>
            <li><a href="page3.html">Item 3</a></li>
            <li><a href="page4.html">Item 4</a></li>
            <li><a href="page5.html">Item 5</a></li>
        </ul>
    </nav>
    <div id="content-container">
        <div id="home">
            <div class="content-block-container">
                <div class="content-block-container-inner">
                    <div id="participate-block" class="content-block text">
                        <h1>How to Participate</h1>
                        <div class="participate-expandable">
                            <a href="#" id="participate-join-expand" class="participate-expandable-trigger">
                                <span class="expandable-icon">+</span>
                                <span class="expandable-text">Join the Challenge</span>
                            </a>
                            <div id="participate-join-hidden" class="expandable-hidden">
                                <p>The challenge submission is based on Docker container. So, participants should
                                    demonstrate basic segmentation skills and the ability to encapsulate their methods
                                    in
                                    Docker. We provide a playground for participants to practice. Participants should
                                </p>

                                <ul>
                                    <li>
                                        Develop any segmentation method (e.g., U-Net) based on the playground training
                                        dast
                                        and encapsulate the method by Docker.
                                    </li>
                                    <li>Use Docker to predict the testing set and record 5-10 minutes of the predicting
                                        process as a video (mp4 format). </li>
                                    <li>Submit the segmentation results <a
                                            href="https://abdomenct-1k-fully-supervised-learning.grand-challenge.org/evaluation/playground/submissions/create/">here</a>
                                        and upload your Docker to <a herf="https://hub.docker.com/">DockerHub</a>. <!--Send the following items to 
                            <a href="mailto:xxx@xxx.com">xxx@xxx.com</a>--><br>(1) docker hub link;<br>
                                        (2) download link to the recorded inference mp4 video;<br>
                                        (3) the screenshot of your playground leaderboard results (Mean DSC>0.8).
                                    </li>
                                </ul>

                                <b></b>After reviewing your submission, we will get back to you with an Entry Number,
                                then
                                you can join the Challenge. We also provide a step-by-step <a
                                    herf="https://github.com/qic999/challenge_test">tutorial</a> if you are not familiar
                                with 3D image segmentation.
                            </div>
                        </div>
                        <div class="participate-expandable">
                            <a href="#" id="participate-download-expand" class="participate-expandable-trigger">
                                <span class="expandable-icon">+</span>
                                <span class="expandable-text">Download the data</span>
                            </a>
                            <div id="participate-download-hidden" class="expandable-hidden">
                                <p>There are three datasets used in our challenge. First, the training dataset,
                                    ImageNetCT-9K, is provided on Google Drive where you can download the ground-truth
                                    masks
                                    and follow the corresponding instructions to download the CT scans. Note that you
                                    can
                                    use external datasets to train your model for better performance. Second, the
                                    validation
                                    dataset, TotalSegmentor, is a public dataset that is used in an instant and
                                    continuously
                                    opened submission-and-validation leaderboard to evaluate your model repetitively.
                                    Last,
                                    the private testing dataset, JHH-1K, reflects a real-world, diverse patient
                                    population
                                    that encompasses a broad spectrum of pathological conditions, age groups, and
                                    demographic backgrounds.
                                </p>
                                <p>
                                    After you finish the registration in the first step, the download link to
                                    ImageNetCT-9K
                                    will be sent to you along with the Entry Number. As for the validation dataset,
                                    please
                                    follow the instructions to download <a
                                        herf="https://github.com/wasserth/TotalSegmentator">TotalSegmentor</a>.</p>
                            </div>
                        </div>
                        <div class="participate-expandable">
                            <a href="#" id="participate-model-expand" class="participate-expandable-trigger">
                                <span class="expandable-icon">+</span>
                                <span class="expandable-text">Create your model</span>
                            </a>
                            <div id="participate-model-hidden" class="expandable-hidden">
                                <p>
                                    The task is to develop a model that can predict high-quality segmentations for
                                    abdominal
                                    organs. The training data consists of several thousands of examples on which models
                                    can
                                    be trained and validated.
                                </p>
                                <p>
                                    Teams are allowed to use other data in addition to the official training set in
                                    order to
                                    construct their models, however, that data must be publicly available as of
                                    1/16/2024.
                                    The same applies to pre-trained weights -- they must have been publicly available
                                    before
                                    the ImageNetCT-9K dataset was released on 1/16. This is to prevent unfair advantages
                                    for
                                    teams that may have amassed large private datasets. All external data use must be
                                    described in detail in each team's accompanying paper (described in the following
                                    section).
                                </p>

                                <p>
                                    Based on the performance we achieved by directly training the model on ImageNetCT-9K
                                    and
                                    evaluated on TotalSegmentor (without post-processing), your model’s performance
                                    should
                                    be higher than the results in the following table:
                                </p>

                                <p>The table will be available soon.</p>

                                <p>Wondering where to start? Some useful tutorials and previous methods are given below:
                                </p>

                                Strategies to improve the segmentation performance:
                                <ul>
                                    <li>Preprocessing: intensity normalization, resampling...</li>
                                    <li>Extensive data augmentations;</li>
                                    <li>Coarse-to-fine (two-stage or cascaded) framework;</li>
                                    <li>Postprocessing: connected component analysis;</li>
                                </ul>

                                Strategies to improve the computational efficiency:
                                <ul>
                                    <li>Whole-volume based input;</li>
                                    <li>Lightweight network modules: residual block with bottleneck, separated
                                        convolutions,
                                        and pyramid pooling;</li>
                                    <li>Accelerate inference by ONNX Runtime, TensorRT...</li>
                                </ul>


                                Training Details and Techniques
                                <ul>
                                    <li>Using a Larger Patch Size</li>

                                    <li>Utilizing a Pre-trained Model based on the Totalsegmentor Dataset</li>

                                    <li>Incorporating Other Publicly Available Data for Training the Same Task</li>
                                </ul>
                            </div>
                        </div>
                        <div class="participate-expandable">
                            <a href="#" id="participate-paper-expand" class="participate-expandable-trigger">
                                <span class="expandable-icon">+</span>
                                <span class="expandable-text">Describe your approach with a short paper</span>
                            </a>
                            <div id="participate-paper-hidden" class="expandable-hidden">
                                <p>​​The primary goal of challenges like KiTS is to objectively assess the performance
                                    of
                                    competing methods. This is only possible if teams provide a complete description of
                                    the
                                    methods they use. Teams should follow the provided template [Overleaf, Google Docs]
                                    and
                                    provide satisfactory answers to every field. Papers should otherwise follow the ISBI
                                    main conference guidelines for paper formatting. Drafts of these papers must be
                                    submitted by 04/15/2024.</p>

                            </div>
                        </div>
                        <div class="participate-expandable">
                            <a href="#" id="participate-submit-expand" class="participate-expandable-trigger">
                                <span class="expandable-icon">+</span>
                                <span class="expandable-text">Submit your predictions (validation leaderboard)</span>
                            </a>
                            <div id="participate-submit-hidden" class="expandable-hidden">
                                <p>Due to a short period of development time, we accept docker testing submissions on
                                    JHH-1k
                                    and segmentation results validation submissions on TotalSegmentator at the
                                    beginning.
                                    The results of the TotalSegmentator will be presented on the Results page and the
                                    ones
                                    of JHH-1K will be evaluated locally by the docker container and presented on the
                                    Testing
                                    Results page.</p>

                                <p>All teams can directly submit the segmentation results on the challenge page to get
                                    the
                                    segmentation accuracy metrics.
                                    Please compress your results by running "zip XXX.zip ./*.nii.gz" and upload the zip
                                    file.
                                </p>
                            </div>
                        </div>
                        <div class="participate-expandable">
                            <a href="#" id="participate-container-expand" class="participate-expandable-trigger">
                                <span class="expandable-icon">+</span>
                                <span class="expandable-text">Submit your algorithm container (testing
                                    leaderboard)</span>
                            </a>
                            <div id="participate-container-hidden" class="expandable-hidden">
                                <p>
                                    The submission should include: (Email subject: YourTeamName-TeamLeaderName-Testing
                                    Submission)</p>
                                <p>(1) a download link to your Docker container (teamname.tar.gz); If the Docker
                                    container
                                    does not work, we will return back the error information to the participants.
                                    Participants with technical failure are allowed to resubmit their algorithms with
                                    one
                                    extra time. When the evaluation is finished, we will return back the evaluation
                                    metrics
                                    via email. All valid submission results will be reported on the leaderboard.</p>

                                <p>(2) a sanity test video record (download example: Google drive, Baidu Netdisk) Please
                                    test your docker on validation case: XXX.nii.gz, XXX.nii.gz, XXX.nii.gz and record
                                    the
                                    prediction process. For each case, the running time should be within 60s.
                                </p>
                                <p>(3) a methodology paper (template) Please carefully read the template and the common
                                    issue before writing the manuscript. The evaluation process mainly focuses on the
                                    paper's completeness. Don't worry about the low wDSC/wNSD. Since this segmentation
                                    task
                                    is very challenging, all attempts are worth sharing with readers. We will not reject
                                    papers because of low wDSC/wNSD.
                                </p>

                                <p>
                                    The submitted Docker container will be evaluated with the following commands. If the
                                    Docker container does not work or the paper does not include all the necessary
                                    information to reproduce the method, we will return back the error information and
                                    review comments to participants.
                                </p>
                                <code>docker load -i teamname.tar.gz<br>
                        docker container run --gpus "device=1" -m 28G --name teamname --rm -v $PWD/IMseg2024_Test/:/workspace/inputs/ -v $PWD/teamname_outputs/:/workspace/outputs/ teamname:latest /bin/bash -c "sh predict.sh"
                        </code>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div id="indicator"></div>
</body>

</html>